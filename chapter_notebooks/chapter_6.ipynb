{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# R-like interface, alternatively you can import statsmodels as import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6E1\n",
    "1. Information criterion must be continuous. \n",
    "2. Information criterion should increase as the number of possibilities increase. This means as the possible outcome increases\n",
    "    it becomes harder to 'hit the target'\n",
    "3. Information criterion should be additive. For example if 2 possible events have a score of 0.3, and another 3 events have a\n",
    "    score of 0.45, the total score of 5 events should be 0.3 + 0.45 = 0.75\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6108643020548935"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6E2\n",
    "# See page 178\n",
    "p = (0.3, 0.7)\n",
    "-sum(p * np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3762266043445461"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6E3\n",
    "# See page 178\n",
    "p = (0.2, 0.25,0.25,0.3)\n",
    "-sum(p * np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6E4\n",
    "# See top of page 179 for L'Hopital's rule\n",
    "p = (1/3, 1/3,1/3)\n",
    "-sum(p * np.log(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6M1\n",
    "(skip first part of question) WAIC is the most general of the three.\n",
    "\n",
    "##### 6M2\n",
    "Model Selection is when we pick the best model with the lowest WAIC score, whereas model averaging is prediction averaging which incorporates what we know about the models' relative accuracy. Model selection disregards the differences between models' WAIC scores, which tells us how confident we should be about models. \n",
    "\n",
    "##### 6M3\n",
    "Model with fewer observations will always have lower WAIC score, because the model is asked to predict less. \n",
    "\n",
    "##### 6M4\n",
    "Page, 191. \"Effective\" number of parameters measures how flexible model is. As priors beomces more restrictive, the model becomes less flexible and thus reducing the number of effective parameters. \n",
    "\n",
    "##### 6M5\n",
    "Priors reduce overfitting because it makes the model skeptical of values outside of the defined prior. If the prior does a good job defining the possible boundries, then the models will be skeptical from outliers and refrain from assiging too much probability to the outliers.\n",
    "\n",
    "##### 6M6\n",
    "Overly restrictive priors prevents the model from learning from data, because it considers large percentage of the data as 'impossible'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>100.965</td>\n",
       "      <td>14.401546</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>152.400</td>\n",
       "      <td>41.163474</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>124.460</td>\n",
       "      <td>19.277660</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>158.750</td>\n",
       "      <td>48.676091</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>149.225</td>\n",
       "      <td>42.240755</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      height     weight   age  male\n",
       "220  100.965  14.401546   5.0     1\n",
       "254  152.400  41.163474  77.0     1\n",
       "511  124.460  19.277660  12.0     0\n",
       "423  158.750  48.676091  28.0     1\n",
       "162  149.225  42.240755  45.0     0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6H1\n",
    "df=pd.read_csv('../Data/Howell1.csv', sep=';', header=0)\n",
    "train_howell, test_howell = train_test_split(df,test_size=0.5,random_state=1000)\n",
    "test_howell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
